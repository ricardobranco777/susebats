#!/usr/bin/env python3
"""
List BATS jobs on o.s.d & o3
"""

import argparse
import os
import sys
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from datetime import datetime, timedelta
from urllib.parse import parse_qs, urlparse

import requests
from requests.exceptions import RequestException

from bats.debug import debugme
from bats.repos import REPOS, find_products, grep_tarball


TIMEOUT = 30

session = requests.Session()


@dataclass
class Job:
    """
    Job class
    """

    name: str
    result: str
    results: list[dict]
    url: str


def get_job_id(
    url_string: str, params: dict[str, list[str]] | None = None
) -> int | None:
    """
    Get job ID from URL with no job ID in URL
    """
    url = urlparse(url_string)
    if not url.query:
        return int(os.path.basename(url.path).removeprefix("t"))

    api_url = f"{url.scheme}://{url.netloc}/api/v1/jobs/overview"
    try:
        got = session.get(api_url, params=params, timeout=TIMEOUT)
        got.raise_for_status()
        data = got.json()
    except RequestException as error:
        print(f"ERROR: {url_string}: {error}", file=sys.stderr)
        return None
    if len(data) != 1:
        return None

    return data[0]["id"]


def get_job(
    url_string: str, verbose: bool = False, build: str | None = None
) -> Job | None:
    """
    Get a job
    """
    if not url_string.startswith(("http:", "https:")):
        url_string = f"https://{url_string}"
    url = urlparse(url_string)

    params: dict[str, list[str]] = parse_qs(url.query)
    if build:
        # Append "-1" to aggregate tests in o.s.d
        if "openqa.suse.de" in url.netloc and not build.endswith("-1"):
            build = f"{build}-1"
        params["build"] = [build]

    job_id = get_job_id(url_string, params=params)
    if job_id is None:
        return None

    api_url = f"{url.scheme}://{url.netloc}/api/v1/jobs/{job_id}"
    if verbose:
        api_url = f"{api_url}/details"
    try:
        got = session.get(api_url, timeout=TIMEOUT)
        got.raise_for_status()
        info = got.json()["job"]
    except RequestException as error:
        print(f"ERROR: {api_url}: {error}", file=sys.stderr)
        return None

    if build and info["settings"]["BUILD"] != build:
        return None

    return Job(
        name=info["name"],
        result=info["result"] if info["result"] != "none" else info["state"],
        results=info.get("testresults") if info["result"] == "failed" else None,
        url=f"{url.scheme}://{url.netloc}/tests/{job_id}",
    )


def get_urls(repo: str) -> list[str]:
    """
    Get URL's from YAML schedules in repo
    """
    return [
        product.url
        for file in grep_tarball(repo, "*.yaml")
        for product in find_products(file)
    ]


def main() -> None:
    """
    Main function
    """
    parser = argparse.ArgumentParser(
        prog="bats_jobs",
        description="list BATS jobs in o.s.d & o3",
        epilog="set GITLAB_TOKEN environment variable for gitlab",
    )
    parser.add_argument("-b", "--build", help="-DAYS_AGO or YYYYMMDD")
    parser.add_argument("-v", "--verbose", action="store_true")
    parser.add_argument("urls", nargs="*", metavar="url")
    args = parser.parse_args()

    if not args.urls:
        args.urls = []
        with ThreadPoolExecutor(max_workers=min(10, len(REPOS))) as executor:
            for urls in executor.map(get_urls, REPOS):
                args.urls.extend(urls)

    build = args.build
    if build and build.startswith("-"):
        today = datetime.now().date()
        date = today - timedelta(days=int(build[1:]))
        build = date.strftime("%Y%m%d")

    with ThreadPoolExecutor(max_workers=min(10, len(args.urls))) as executor:
        for job in executor.map(
            lambda u: get_job(u, verbose=args.verbose, build=build), args.urls
        ):
            if job is None:
                continue
            print_job(job)


def print_job(job: Job) -> None:
    """
    Print job
    """
    job.result = job.result.upper() if job.result == "failed" else job.result
    print(f"{job.result:10}  {job.url:<42}  {job.name}")
    # Skip non-failed jobs
    if job.result != "FAILED" or not job.results:
        return
    for result in job.results:
        # Skip non-failed modules
        if result["result"] == "failed":
            if not result["has_parser_text_result"]:
                print(f"\t{result['name']}")
                continue
            for test in result["details"]:
                # Skip non-failed sub-tests
                if test["result"] == "fail":
                    print(f"\t{result['name']:<30}  {test['text_data']}")


if __name__ == "__main__":
    if os.getenv("DEBUG"):
        session.hooks["response"].append(debugme)
    try:
        main()
    except KeyboardInterrupt:
        sys.exit(1)
    finally:
        session.close()
