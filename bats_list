#!/usr/bin/env python3
"""
List skipped BATS tests on all schedules
"""

import argparse
import io
import logging
import re
import os
import sys
import tarfile
from fnmatch import fnmatch
from typing import Iterator

import requests
from requests.exceptions import RequestException
import yaml

GITLAB_TOKEN = os.environ.get("GITLAB_TOKEN")

DIRS = (
    "~/suse/opensuse-jobgroups/",
    "~/suse/qac-openqa-yaml/",
)

REPOS = (
    "https://github.com/os-autoinst/opensuse-jobgroups/archive/refs/heads/master.tar.gz",
    "https://gitlab.suse.de/qac/qac-openqa-yaml/-/archive/master/qac-openqa-yaml-master.tar.gz",
)


SKIP = re.compile(r"BATS_SKIP")
TESTSUITE = re.compile(r"(buildah|podman)_testsuite$")


def find_file(file: io.TextIOWrapper) -> None:
    """
    Find settings in file
    """
    try:
        data = yaml.safe_load(file)
    except yaml.YAMLError:
        return

    if "scenarios" not in data:
        return

    for products in data["scenarios"].values():
        for product, tests in products.items():
            for test in filter(lambda t: isinstance(t, dict), tests):
                for job in sorted(filter(TESTSUITE.search, test.keys())):
                    print(f"{product}\t{job}")
                    for setting in sorted(filter(SKIP.search, test[job]["settings"])):
                        print(f"\t{setting}='{test[job]['settings'][setting]}'")


def grep_dir(
    directory: str,
    regex: re.Pattern,
    file_pattern: str,
    ignore_dirs: list[str] | None = None,
) -> Iterator[str]:
    """
    Recursive grep
    """
    if ignore_dirs is None:
        ignore_dirs = []
    for root, dirs, files in os.walk(directory):
        for ignore in set(ignore_dirs) & set(dirs):
            dirs.remove(ignore)
        for file in files:
            if fnmatch(file, file_pattern):
                file = os.path.join(root, file)
                with open(file, encoding="utf-8") as f:
                    if regex.search(f.read(), re.M):
                        yield file


def grep_tarball(
    url: str,
    file_pattern: str,
) -> Iterator[io.TextIOWrapper]:
    """
    Downloads a tarball and return the content of files
    """
    headers = {}
    if "gitlab" in url:
        headers["PRIVATE-TOKEN"] = GITLAB_TOKEN
    try:
        response = requests.get(url, headers=headers, stream=True, timeout=10)
        response.raise_for_status()
    except RequestException as error:
        logging.error("%s: %s", url, error)
        sys.exit(1)
    data = io.BytesIO(response.content)
    try:
        with tarfile.open(fileobj=data, mode="r:gz") as tar:
            for elem in tar.getmembers():
                if elem.isfile() and fnmatch(elem.name, file_pattern):
                    file = tar.extractfile(elem)
                    if file is not None:
                        yield io.TextIOWrapper(io.BytesIO(file.read()))
    except tarfile.ReadError as error:
        # May fail because GITLAB_TOKEN is not set
        logging.error("%s: %s", url, error)


def fetch_remote() -> None:
    """
    Fetch info from URL containing tarball to remote repo
    """
    for repo in REPOS:
        for file in grep_tarball(repo, "*.yaml"):
            find_file(file)


def fetch_local() -> None:
    """
    Fetch info from local cloned repo
    """
    for directory in DIRS:
        for file in grep_dir(os.path.expanduser(directory), SKIP, "*.yaml", [".git"]):
            with open(file, encoding="utf-8") as f:
                find_file(f)


def main() -> None:
    """
    Main function
    """
    parser = argparse.ArgumentParser(
        prog="bats_list",
        description="list skipped BATS tests per product",
        epilog="set GITLAB_TOKEN environment variable for --remote",
    )
    parser.add_argument(
        "--remote", action="store_true", help="Fetch info from remote repos"
    )
    args = parser.parse_args()

    if args.remote:
        fetch_remote()
    else:
        fetch_local()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        sys.exit(1)
